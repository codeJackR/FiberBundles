{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from dipy.io.streamline import load_trk\n",
    "from dipy.viz import window, actor\n",
    "import math\n",
    "from nibabel import trackvis as tv\n",
    "from dipy.tracking.streamline import Streamlines\n",
    "from dipy.segment.clustering import QuickBundles\n",
    "from dipy.io.pickles import save_pickle\n",
    "from dipy.data import get_data\n",
    "from dipy.segment.metric import mdf\n",
    "from dipy.segment.metric import AveragePointwiseEuclideanMetric\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_streamlines(streamlines): #function to visualize streamlines\n",
    "    \n",
    "    ren = window.Renderer()\n",
    "    ren.add(actor.line(streamlines))\n",
    "    window.show(ren)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_multiple_streamlines(streamline1,streamline2): #function to visualize streamlines\n",
    "    \n",
    "    ren = window.Renderer()\n",
    "    ren.add(actor.line(streamline1))\n",
    "    ren.add(actor.line(streamline2,colors=(0,1,1)))\n",
    "    window.show(ren)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " load brain (tractogram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "brain, b_hr = load_trk(\"brain.trk\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "load Arcuate Fasciculus left fiber bundle (AF_L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "bundle, bn_hr = load_trk(\"AF_L.trk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cst, bn_hr = load_trk(\"CST_recognized.trk\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "let's visualize them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first brain\n",
    "\n",
    "#show_streamlines(brain)\n",
    "show_multiple_streamlines(brain[1953:1954], brain[1950+81:1950+82])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now bundle\n",
    "\n",
    "show_streamlines(bundle[3:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "331"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(bundle[0].shape)\n",
    "len(bundle[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get labels\n",
    "\n",
    "def getLabels(brain, bundle):\n",
    "    labels = np.zeros(len(brain))\n",
    "    npbrain = np.array(brain)\n",
    "    for i in range(len(bundle)):\n",
    "        for j in range(len(brain)):\n",
    "            if((npbrain[j].shape[0]==bundle[i].shape[0])):\n",
    "    #         print(i,j)\n",
    "                if np.allclose(npbrain[j], bundle[i]):\n",
    "                    labels[j] = 1\n",
    "                    break\n",
    "        if(i%100==0):\n",
    "            print(i,end=\" \")\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 100 200 300 400 500 600 700 800 900 1000 1100 1200 1300 1400 1500 1600 1700 1800 1900 "
     ]
    }
   ],
   "source": [
    "labels = np.zeros(len(brain))\n",
    "l = getLabels(brain, bundle)\n",
    "labels[l==l] = 1\n",
    "# l = getLabels(brain, cst)\n",
    "# labels[l==l] = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find Frechet distance\n",
    "# From : https://gist.github.com/MaxBareiss/ba2f9441d9455b56fbc9\n",
    "\n",
    "# Euclidean distance.\n",
    "def euc_dist(pt1,pt2):\n",
    "    return math.sqrt((pt2[0]-pt1[0])*(pt2[0]-pt1[0])+(pt2[1]-pt1[1])*(pt2[1]-pt1[1]))\n",
    "\n",
    "def _c(ca,i,j,P,Q):\n",
    "    if ca[i,j] > -1:\n",
    "        return ca[i,j]\n",
    "    elif i == 0 and j == 0:\n",
    "        ca[i,j] = euc_dist(P[0],Q[0])\n",
    "    elif i > 0 and j == 0:\n",
    "        ca[i,j] = max(_c(ca,i-1,0,P,Q),euc_dist(P[i],Q[0]))\n",
    "    elif i == 0 and j > 0:\n",
    "        ca[i,j] = max(_c(ca,0,j-1,P,Q),euc_dist(P[0],Q[j]))\n",
    "    elif i > 0 and j > 0:\n",
    "        ca[i,j] = max(min(_c(ca,i-1,j,P,Q),_c(ca,i-1,j-1,P,Q),_c(ca,i,j-1,P,Q)),euc_dist(P[i],Q[j]))\n",
    "    else:\n",
    "        ca[i,j] = float(\"inf\")\n",
    "    return ca[i,j]\n",
    "\n",
    "\"\"\" Computes the discrete frechet distance between two polygonal lines\n",
    "Algorithm: http://www.kr.tuwien.ac.at/staff/eiter/et-archive/cdtr9464.pdf\n",
    "P and Q are arrays of 2-element arrays (points)\n",
    "\"\"\"\n",
    "def frechetDist(P,Q):\n",
    "    ca = np.ones((len(P),len(Q)))\n",
    "    ca = np.multiply(ca,-1)\n",
    "    return _c(ca,len(P)-1,len(Q)-1,P,Q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fast Dynamic time warping\n",
    "# From: https://github.com/slaypni/fastdtw\n",
    "\n",
    "import numpy as np\n",
    "from fastdtw import fastdtw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dipy.align.streamlinear import BundleMinDistanceMetric\n",
    "from dipy.align.streamlinear import set_number_of_points\n",
    "# BundleMinDistanceMetric().distance(cBrain3D[0],cBrain3D[1])\n",
    "\n",
    "def bmd(a,b):\n",
    "    static = set_number_of_points(a, len(a))\n",
    "    moving = set_number_of_points(b, len(b))\n",
    "    BMD = BundleMinDistanceMetric()\n",
    "    BMD.setup(static, moving)\n",
    "    x0 = np.array([0, 0, 0, 0, 0, 0, 1., 1., 1, 0, 0, 0])  # affine\n",
    "    bmd_value = BMD.distance(x0.tolist())\n",
    "    return bmd_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "bmd(brain3D[0],brain3D[7])\n",
    "# brain3D[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get distance between 2 curves\n",
    "from scipy.spatial.distance import euclidean\n",
    "\n",
    "def distanceBetweenCurves(c1, c2, algo='fastdtw'):\n",
    "    if algo=='fastdtw':\n",
    "        distance, path = fastdtw(c1,c2, radius = 1, dist = euclidean) # check out the 'radius' parameter to tune the distance\n",
    "        return distance\n",
    "    elif algo=='frechet':\n",
    "        return frechetDist(c1,c2)\n",
    "    elif algo=='bmd':\n",
    "        return bmd(c1,c2)\n",
    "    elif algo=='mdf':\n",
    "        return mdf(c1,c2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "def project2D(streamline):\n",
    "    pca = PCA(n_components=2)\n",
    "    newBundle = pca.fit_transform(streamline)\n",
    "#     newStreamline = Streamlines([(np.hstack((newBundle,np.zeros((newBundle.shape[0])).reshape((-1,1)))))])\n",
    "    newStreamline = Streamlines([newBundle])\n",
    "    return newStreamline, pca.components_, pca.singular_values_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(pca.explained_variance_ratio_) \n",
    "# print(pca.singular_values_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "# st = Streamlines([newBundle])\n",
    "def convertToAngles(streamline2D):\n",
    "    streamline2D = np.array(streamline2D)\n",
    "#     print((streamline2D))\n",
    "    angles = np.zeros(streamline2D.shape[0])\n",
    "    angles[0] = 1\n",
    "#     print(streamline2D.shape)\n",
    "    # handle the direction of start\n",
    "#     print(streamline2D.shape)\n",
    "    for point in range(1,streamline2D.shape[0]):\n",
    "#         print(point)\n",
    "        diff = streamline2D[point] - streamline2D[point-1]\n",
    "#         print(streamline2D[point], streamline2D[point-1])\n",
    "        if(diff[0]==0):\n",
    "            angles[point] = angles[point-1]\n",
    "        else:\n",
    "            angles[point] = math.degrees(math.atan(diff[1]/diff[0]))\n",
    "    return angles\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "# center the data\n",
    "def centerData(data):\n",
    "    for i in range(len(data)):\n",
    "        mean = np.mean(data[i],axis=0)\n",
    "        data[i] = data[i]-mean\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDataLD(bundle):\n",
    "    data2D = []\n",
    "    angularData = []\n",
    "    eigenValues = []\n",
    "    eigenVecs = []\n",
    "    for index in range(len(bundle)):\n",
    "        newStreamline, vecs, singVal = project2D(np.array(bundle[index]))\n",
    "        data2D.append(newStreamline[0][:,:2])\n",
    "        eigenValues.append(singVal)\n",
    "        eigenVecs.append(vecs)\n",
    "        # append these values to store them \n",
    "        streamlineAsAngle = convertToAngles(newStreamline[0])\n",
    "#         print(streamlineAsAngle)\n",
    "        angularData.append(streamlineAsAngle)\n",
    "    \n",
    "    return angularData, data2D, eigenVecs, eigenValues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cBrain = centerData(np.array(brain))\n",
    "brain1D, brain2D, eigenVecs, eigenValues = getDataLD(cBrain[1950:2150])\n",
    "brain3D = np.array(cBrain[1950:2150]).tolist()\n",
    "# show_multiple_streamlines(newStreamline,bundle[0:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set labels\n",
    "labels = np.ones(len(brain1D))\n",
    "labels[50:]*=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cBrain1D = centerData(brain1D)\n",
    "# cBrain2D = centerData(brain2D)\n",
    "# cBrain3D = centerData(brain3D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From https://www.geeksforgeeks.org/program-to-find-equation-of-a-plane-passing-through-3-points/\n",
    "# get equation of plane from 3 points\n",
    "def getPlaneEquation(p1, p2, p3):    \n",
    "    a1 = p2[0] - p1[0] \n",
    "    b1 = p2[1] - p1[1] \n",
    "    c1 = p2[2] - p1[2] \n",
    "    a2 = p3[0] - p1[0] \n",
    "    b2 = p3[1] - p1[1] \n",
    "    c2 = p3[2] - p1[2]\n",
    "    a = b1 * c2 - b2 * c1 \n",
    "    b = a2 * c1 - a1 * c2 \n",
    "    c = a1 * b2 - b1 * a2 \n",
    "    d = (- a * x1 - b * y1 - c * z1) \n",
    "    norm = np.sqrt(a**2+b**2+c**2)\n",
    "    return a/norm,b/norm,c/norm,d/norm\n",
    "#     print \"equation of plane is \", \n",
    "#     print a, \"x +\", \n",
    "#     print b, \"y +\", \n",
    "#     print c, \"z +\", \n",
    "#     print d, \"= 0.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "# brain data in a particular plane but in 3D space\n",
    "x2DBrain3D = [(np.dot(eigenVecs[i].T, stream.T)).T for i, stream in enumerate(brain2D)]\n",
    "# (eigenVecs[0]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x2DBrain3D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_multiple_streamlines(x2DBrain3D[0:1],brain3D[0:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.5425549587971726,\n",
       " 0.22090170225680855,\n",
       " 0.8104545358159473,\n",
       " 29.414827740378687)"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getPlaneEquation(x2DBrain3D[4][5], x2DBrain3D[4][6], x2DBrain3D[4][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rodriguesRotation(axis, vector, angle):\n",
    "    # axis should be a unit vector\n",
    "    return vector*np.cos(angle) + (np.cross(axis, vector))*np.sin(angle) + axis*(np.dot(axis,vector))*(1-np.cos(angle))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.0000000e+00, 0.0000000e+00, 2.4492936e-16])"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rodriguesRotation(np.array([0,1,0]), np.array([1,0,0]), 2*np.pi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "atheta = 0\n",
    "ztheta = 0\n",
    "subSegments = 7 # using odd value to prevent redunduncy in the discrete planes\n",
    "subAngles = np.pi/subSegments\n",
    "noOfPlanes = subSegments*subSegments\n",
    "discretePlanes = []\n",
    "for a in range(subSegments):\n",
    "    vec = np.array([np.cos(atheta+(a*subAngles)), np.sin(atheta+(a*subAngles)), 0])\n",
    "    axis = np.array([np.cos((np.pi/2)+atheta+(a*subAngles)), np.sin((np.pi/2)+atheta+(a*subAngles)), 0])\n",
    "    for z in range(subSegments):\n",
    "        discretePlanes.append(rodriguesRotation(axis, vec, ztheta+(z*subAngles)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "discretePlanes = np.array(discretePlanes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ev = eigenVecs[3][0]\n",
    "# x1 = 10\n",
    "# y1=20\n",
    "# z1 = (-ev[0]*x1 + -ev[1]*y1)/ev[2]\n",
    "\n",
    "# x2 = 60\n",
    "# y2=40\n",
    "# z2 = (-ev[0]*x2 + -ev[1]*y2)/ev[2]\n",
    "\n",
    "# x3 = 25\n",
    "# y3=86\n",
    "# z3 = (-ev[0]*x3 + -ev[1]*y3)/ev[2]\n",
    "\n",
    "# x4 = 36\n",
    "# y4=61\n",
    "# z4 = (-ev[0]*x4 + -ev[1]*y4)/ev[2]\n",
    "\n",
    "# tempStream2 = np.array([[x1,y1,z1],[x2,y2,z2], [x3,y3,z3]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (brain3D[0]).shape\n",
    "# temp = Streamlines([(np.hstack((brain2D[3],np.zeros((brain2D[3].shape[0])).reshape((-1,1)))))])\n",
    "# show_multiple_streamlines(temp,tempStream)\n",
    "# print(len(brain1D),len(brain2D),len(brain3D))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-2.9802322e-08"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dot((eigenVecs[3][1]), (eigenVecs[3][2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17736.3150430503"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distanceBetweenCurves(cBrain3D[3], cBrain3D[81], 'fastdtw')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create covariance matrix\n",
    "\n",
    "# cov = np.zeros((len(cBrain3D), len(cBrain3D)))\n",
    "# for i in range(len(cBrain3D)):\n",
    "#     for j in range(len(cBrain3D)):\n",
    "#         cov[i][j] = distanceBetweenCurves(cBrain3D[i], cBrain3D[j], 'frechet')\n",
    "#     print(i, end=\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cov' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-a4400d09b329>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Save\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'covarianceMDF3D.pkl'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcov\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'cov' is not defined"
     ]
    }
   ],
   "source": [
    "# store the covariance matrix variable to disk\n",
    "\n",
    "# Save\n",
    "with open('covarianceMDF3D.pkl', 'wb') as f:\n",
    "    pickle.dump(cov, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve\n",
    "cov = []\n",
    "with open('covariance3D.pkl', 'rb') as f:\n",
    "    cov = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 200)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cov.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0xb65804240>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib qt\n",
    "plt.imshow(cov)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3 µs, sys: 1 µs, total: 4 µs\n",
      "Wall time: 5.72 µs\n"
     ]
    }
   ],
   "source": [
    "# get centroids for the bundles\n",
    "\n",
    "%time\n",
    "def getCentroids(streamlines, noOfCentroids, pointsInCentroid=400):\n",
    "    streamlines = [set_number_of_points(streamline, nb_points=pointsInCentroid) for streamline in streamlines]\n",
    "    thresh=1\n",
    "    qb = QuickBundles(threshold=thresh, metric=AveragePointwiseEuclideanMetric())\n",
    "    clusters = qb.cluster(streamlines)\n",
    "    length = len(clusters.centroids)\n",
    "    prev = 0\n",
    "    flag=False\n",
    "    while(length!=noOfCentroids):\n",
    "        if(length>noOfCentroids):\n",
    "            if flag:\n",
    "                temp = thresh\n",
    "                thresh= thresh + (thresh-prev)/2.0\n",
    "                prev = temp\n",
    "            else:\n",
    "                prev=thresh\n",
    "                thresh *= 2.0\n",
    "        else:\n",
    "            temp = thresh\n",
    "            thresh = prev+(thresh-prev)/2.0\n",
    "            flag = True\n",
    "        qb = QuickBundles(threshold=thresh, metric=AveragePointwiseEuclideanMetric())\n",
    "        clusters = qb.cluster(streamlines)\n",
    "        length = len(clusters)\n",
    "    return np.array(clusters.centroids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3 µs, sys: 0 ns, total: 3 µs\n",
      "Wall time: 7.87 µs\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "def getAllCentroids(brainData, labels, noOfBundles, noOfCentroids=3):\n",
    "    centroids = []\n",
    "    for n in range(noOfBundles):\n",
    "        if n==0:\n",
    "            c = getCentroids(brainData[labels==n], noOfCentroids)\n",
    "            centroids = c.reshape((1,)+c.shape)\n",
    "        else:\n",
    "            centroids = np.vstack((centroids, getCentroids(brainData[labels==n], noOfCentroids).reshape((1,)+c.shape)))\n",
    "    return centroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shape = (no of bundles, no of centroids in each bundle, no of points in each centroid, dimensions of the points)\n",
    "centroidMat = getAllCentroids(np.array(cBrain3D),labels, len(np.unique(labels)))\n",
    "\n",
    "# Save\n",
    "with open('centroidMat.pkl', 'wb') as f:\n",
    "    pickle.dump(centroidMat, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve\n",
    "cov = []\n",
    "with open('centroidMat.pkl', 'rb') as f:\n",
    "    centroidMat = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 3, 400, 3)"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "centroidMat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get distance of a streamline from all the centroids\n",
    "def getDistToCentroids(streamline):\n",
    "    global centroidMat\n",
    "    distMat = np.zeros((centroidMat.shape[0], centroidMat.shape[1]))\n",
    "    for i in range(distMat.shape[0]):\n",
    "        for j in range(distMat.shape[1]):\n",
    "            distMat[i][j] = distanceBetweenCurves(centroidMat[i][j], streamline, 'fastdtw')\n",
    "    return distMat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get probability of getting a bundle given a streamline(shape)\n",
    "def pB_S(streamline, metric='min'):\n",
    "    distMat = getDistToCentroids(streamline)\n",
    "    if metric=='min':\n",
    "        distToBundles = np.min(distMat, axis=1)\n",
    "    elif metric=='avg':\n",
    "        distToBundles = np.mean(distMat, axis=1)\n",
    "    \n",
    "    probabilities = 1/distToBundles\n",
    "    probabilities /= np.sum(probabilities)\n",
    "    return probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.27219556 0.72780444]\n",
      "[0.44146201 0.55853799]\n",
      "[0.54573283 0.45426717]\n",
      "[0.29714698 0.70285302]\n",
      "[0.42486052 0.57513948]\n",
      "[0.22322003 0.77677997]\n",
      "[0.15518991 0.84481009]\n",
      "[0.13141942 0.86858058]\n",
      "[0.53354626 0.46645374]\n",
      "[0.2731943 0.7268057]\n",
      "[0.49822328 0.50177672]\n",
      "[0.55580359 0.44419641]\n",
      "[0.51954827 0.48045173]\n",
      "[0.45389317 0.54610683]\n",
      "[0.37544186 0.62455814]\n",
      "[0.26141036 0.73858964]\n",
      "[0.28601226 0.71398774]\n",
      "[0.43569856 0.56430144]\n",
      "[0.27688823 0.72311177]\n",
      "[0.60175203 0.39824797]\n",
      "[0.46373804 0.53626196]\n",
      "[0.37769523 0.62230477]\n",
      "[0.48710457 0.51289543]\n",
      "[0.59725709 0.40274291]\n",
      "[0.49291974 0.50708026]\n",
      "[0.33651543 0.66348457]\n",
      "[0.36177766 0.63822234]\n",
      "[0.28080104 0.71919896]\n",
      "[0.53593862 0.46406138]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-84-b41d74bcbbe6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpB_S\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcBrain3D\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-79-a4eef2da3bdb>\u001b[0m in \u001b[0;36mpB_S\u001b[0;34m(streamline, metric)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# get probability of getting a bundle given a streamline(shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mpB_S\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstreamline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetric\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'min'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mdistMat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetDistToCentroids\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstreamline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmetric\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m'min'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mdistToBundles\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdistMat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-78-2523ec4215ef>\u001b[0m in \u001b[0;36mgetDistToCentroids\u001b[0;34m(streamline)\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdistMat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdistMat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m             \u001b[0mdistMat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdistanceBetweenCurves\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcentroidMat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstreamline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'fastdtw'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdistMat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-21-8aa722380113>\u001b[0m in \u001b[0;36mdistanceBetweenCurves\u001b[0;34m(c1, c2, algo)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mdistanceBetweenCurves\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malgo\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'fastdtw'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0malgo\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m'fastdtw'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0mdistance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfastdtw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mc2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mradius\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meuclidean\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# check out the 'radius' parameter to tune the distance\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdistance\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0malgo\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m'frechet'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mfastdtw/_fastdtw.pyx\u001b[0m in \u001b[0;36mfastdtw._fastdtw.fastdtw\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mfastdtw/_fastdtw.pyx\u001b[0m in \u001b[0;36mfastdtw._fastdtw.__fastdtw\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mfastdtw/_fastdtw.pyx\u001b[0m in \u001b[0;36mfastdtw._fastdtw.__fastdtw\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mfastdtw/_fastdtw.pyx\u001b[0m in \u001b[0;36mfastdtw._fastdtw.__fastdtw\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mfastdtw/_fastdtw.pyx\u001b[0m in \u001b[0;36mfastdtw._fastdtw.__fastdtw\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mfastdtw/_fastdtw.pyx\u001b[0m in \u001b[0;36mfastdtw._fastdtw.__dtw\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/scipy/spatial/distance.py\u001b[0m in \u001b[0;36meuclidean\u001b[0;34m(u, v, w)\u001b[0m\n\u001b[1;32m    596\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m     \"\"\"\n\u001b[0;32m--> 598\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mminkowski\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    599\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/scipy/spatial/distance.py\u001b[0m in \u001b[0;36mminkowski\u001b[0;34m(u, v, p, w)\u001b[0m\n\u001b[1;32m    499\u001b[0m             \u001b[0mroot_w\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    500\u001b[0m         \u001b[0mu_v\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mroot_w\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mu_v\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 501\u001b[0;31m     \u001b[0mdist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mu_v\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mord\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    502\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdist\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/scipy/linalg/misc.py\u001b[0m in \u001b[0;36mnorm\u001b[0;34m(a, ord, axis, keepdims)\u001b[0m\n\u001b[1;32m    135\u001b[0m     \"\"\"\n\u001b[1;32m    136\u001b[0m     \u001b[0;31m# Differs from numpy only in non-finite handling and the use of blas.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m     \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray_chkfinite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0;31m# Only use optimized norms if axis and keepdims are not specified.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/numpy/lib/function_base.py\u001b[0m in \u001b[0;36masarray_chkfinite\u001b[0;34m(a, dtype, order)\u001b[0m\n\u001b[1;32m    457\u001b[0m     \"\"\"\n\u001b[1;32m    458\u001b[0m     \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 459\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchar\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtypecodes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'AllFloat'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfinite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    460\u001b[0m         raise ValueError(\n\u001b[1;32m    461\u001b[0m             \"array must not contain infs or NaNs\")\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/numpy/core/_methods.py\u001b[0m in \u001b[0;36m_all\u001b[0;34m(a, axis, dtype, out, keepdims)\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mumr_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_count_reduce_items\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i in range(200):\n",
    "    print(pB_S(cBrain3D[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# probability of a centroid given a particular streamline(shape)\n",
    "# dimensions: (no of bundles, no of centroids)\n",
    "def pC_S(streamline):\n",
    "    dist = 1/getDistToCentroids(streamline)\n",
    "    return dist/np.sum(dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.5617449 ,  0.27052209, -0.78183148])"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# centroidMat.reshape((2,3)).shape\n",
    "# (np.dot(eigenVecs[i].T, stream.T)).T\n",
    "discretePlanes[9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get angle between 2 planes\n",
    "def dihedralAngle(a, b):\n",
    "    temp =  np.arccos((np.dot(a,b))/(np.linalg.norm(a)*np.linalg.norm(b)))\n",
    "    if temp>10000:\n",
    "        print(a,b)\n",
    "    return temp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dimensions: (total number of centroids, number of discrete planes)\n",
    "def pP_C():\n",
    "    probabilities = np.zeros((centroidMat.shape[0]*centroidMat.shape[1], noOfplanes))\n",
    "    for i in range(centroidMat.shape[0]):\n",
    "        for j in range(centroidMat.shape[1]):\n",
    "            cent, evecs, evalue = project2D(centerData(centroidMat[i][j]))\n",
    "            PCAedCentroid = (np.dot(evecs.T, np.array(cent[0]).T)).T\n",
    "            a,b,c,d = getPlaneEquation(PCAedCentroid[0],PCAedCentroid[1],PCAedCentroid[2])\n",
    "            for k in range(noOfplanes):\n",
    "                probabilities[centroidMat.shape[1]*i+j][k] = dihedralAngle(np.array([a,b,c]), discretePlanes[k])\n",
    "            \n",
    "    probabilities = 1.0/probabilities\n",
    "    probabilities /= np.sum(probabilities)\n",
    "    return probabilities\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8077343472643393"
      ]
     },
     "execution_count": 315,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dihedralAngle(np.array([-0.5775682004691819, -0.5773971386380066, -0.5770853646553805]), discretePlanes[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00180926, 0.00214587, 0.0026757 , 0.00353153, 0.00491041,\n",
       "        0.00635999, 0.00574193, 0.00161481, 0.00194924, 0.00247465,\n",
       "        0.00338919, 0.00531405, 0.01071866, 0.01189927, 0.00157297,\n",
       "        0.00191111, 0.00243673, 0.00336148, 0.00540985, 0.01352217,\n",
       "        0.02034247, 0.00169688, 0.00202889, 0.00255513, 0.00344713,\n",
       "        0.00513376, 0.00807345, 0.00774975, 0.00196083, 0.00231411,\n",
       "        0.00285246, 0.00364976, 0.00465632, 0.00517742, 0.00452014,\n",
       "        0.0023831 , 0.00282705, 0.00340165, 0.00397422, 0.00417681,\n",
       "        0.0038127 , 0.0032101 , 0.00305274, 0.00375887, 0.00439424,\n",
       "        0.00441289, 0.00379357, 0.00308258, 0.00253   ],\n",
       "       [0.0041328 , 0.00304622, 0.00237981, 0.00195927, 0.00169655,\n",
       "        0.00157389, 0.00161675, 0.00572136, 0.00356186, 0.00256738,\n",
       "        0.00200651, 0.00165283, 0.00142971, 0.00141048, 0.00635445,\n",
       "        0.0037045 , 0.00261189, 0.00201689, 0.0016433 , 0.00138948,\n",
       "        0.00134074, 0.00491895, 0.00333444, 0.00249011, 0.00198774,\n",
       "        0.00167012, 0.00149143, 0.00150113, 0.00353902, 0.00277422,\n",
       "        0.00226148, 0.00192643, 0.00172742, 0.001663  , 0.00174268,\n",
       "        0.00268087, 0.00227884, 0.0020053 , 0.00184703, 0.00180417,\n",
       "        0.00187932, 0.00206882, 0.00214947, 0.00189919, 0.00176981,\n",
       "        0.00176549, 0.00188663, 0.00212856, 0.00250384],\n",
       "       [0.00416637, 0.00306682, 0.00239258, 0.0019674 , 0.00170131,\n",
       "        0.00157495, 0.00161371, 0.0057959 , 0.00359009, 0.00258152,\n",
       "        0.00201469, 0.00165778, 0.00143169, 0.00140687, 0.00642331,\n",
       "        0.00372934, 0.00262462, 0.00202469, 0.00164866, 0.00139365,\n",
       "        0.00133889, 0.00493037, 0.00334643, 0.00249916, 0.00199479,\n",
       "        0.001676  , 0.00149629, 0.00150291, 0.0035339 , 0.00277701,\n",
       "        0.00226675, 0.00193259, 0.0017339 , 0.00166889, 0.00174674,\n",
       "        0.00267365, 0.00227771, 0.002008  , 0.00185242, 0.00181128,\n",
       "        0.001887  , 0.00207608, 0.00214259, 0.00189668, 0.00177118,\n",
       "        0.00177038, 0.00189434, 0.0021387 , 0.00251635],\n",
       "       [0.00414258, 0.00304968, 0.00238083, 0.00195913, 0.00169559,\n",
       "        0.00157219, 0.00161478, 0.00572948, 0.003563  , 0.0025673 ,\n",
       "        0.00200606, 0.00165213, 0.00142854, 0.00140925, 0.00634186,\n",
       "        0.00370098, 0.00261036, 0.00201611, 0.00164291, 0.00138951,\n",
       "        0.00134171, 0.00490268, 0.00332846, 0.00248754, 0.00198668,\n",
       "        0.00167   , 0.00149234, 0.00150288, 0.00352938, 0.00276889,\n",
       "        0.00225866, 0.00192521, 0.00172749, 0.00166429, 0.00174493,\n",
       "        0.00267536, 0.00227489, 0.00200273, 0.00184578, 0.0018043 ,\n",
       "        0.00188083, 0.00207167, 0.0021462 , 0.00189639, 0.00176767,\n",
       "        0.00176433, 0.00188669, 0.00213005, 0.00250732],\n",
       "       [0.00181003, 0.00214627, 0.0026754 , 0.00352933, 0.00490229,\n",
       "        0.00634065, 0.00572845, 0.0016148 , 0.00194885, 0.00247366,\n",
       "        0.00338668, 0.00530569, 0.01066788, 0.01186104, 0.00157216,\n",
       "        0.00191002, 0.00243506, 0.00335849, 0.00540293, 0.01349597,\n",
       "        0.0205239 , 0.00169551, 0.00202711, 0.00255267, 0.00344351,\n",
       "        0.00512906, 0.00808093, 0.00777711, 0.001959  , 0.00231153,\n",
       "        0.00284891, 0.00364529, 0.00465328, 0.00518156, 0.00452808,\n",
       "        0.00238065, 0.00282319, 0.00339625, 0.00396864, 0.00417454,\n",
       "        0.0038145 , 0.00321335, 0.00304941, 0.00375239, 0.00438501,\n",
       "        0.00440598, 0.0037915 , 0.00308311, 0.00253141],\n",
       "       [0.00180979, 0.00214578, 0.00267451, 0.00352765, 0.00489912,\n",
       "        0.00633719, 0.0057287 , 0.00161449, 0.00194836, 0.00247284,\n",
       "        0.00338512, 0.00530189, 0.01065541, 0.01186967, 0.00157183,\n",
       "        0.00190952, 0.00243426, 0.00335696, 0.00539894, 0.01347168,\n",
       "        0.0205718 , 0.00169525, 0.00202664, 0.00255184, 0.00344191,\n",
       "        0.00512551, 0.0080744 , 0.00777829, 0.00195884, 0.00231109,\n",
       "        0.00284799, 0.00364353, 0.00465039, 0.0051791 , 0.0045277 ,\n",
       "        0.00238063, 0.00282277, 0.00339513, 0.00396659, 0.00417223,\n",
       "        0.00381307, 0.00321286, 0.00304971, 0.00375205, 0.00438334,\n",
       "        0.00440346, 0.00378958, 0.00308206, 0.00253093]])"
      ]
     },
     "execution_count": 316,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pP_C()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#show_streamlines(cst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#show_multiple_streamlines(bundle,cst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "let's see its data type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bundle # whole bundle, made of several streamlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ((brain)[0]).shape# number of streamlines in bundle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bundle[1] #one streamline in bundle\n",
    "# (np.array(bundle)[0]).shape\n",
    "# np.array(bundle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (bundle[1].shape) #one point on one streamline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "npbrain = np.array(brain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# npbrain[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(bundle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "these are x, y and z co-ordinates of the point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 100 200 300 400 500 600 700 800 900 1000 1100 1200 1300 1400 1500 1600 1700 1800 1900 "
     ]
    }
   ],
   "source": [
    "# get labels\n",
    "\n",
    "def getLabels(brain, bundle):\n",
    "    labels = np.zeros(len(brain))\n",
    "    npbrain = np.array(brain)\n",
    "    for i in range(len(bundle)):\n",
    "        for j in range(len(brain)):\n",
    "            if((npbrain[j].shape[0]==bundle[i].shape[0])):\n",
    "    #         print(i,j)\n",
    "                if np.allclose(npbrain[j], bundle[i]):\n",
    "                    labels[j] = 1\n",
    "                    break\n",
    "        if(i%100==0):\n",
    "            print(i,end=\" \")\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# npbrain[0].shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_pts = [len(streamline) for streamline in bundle]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dipy.tracking.streamline import (set_number_of_points, nbytes,select_random_set_of_streamlines)\n",
    "newStreamlines = set_number_of_points(bundle,101)\n",
    "n_pts_ds = [len(streamline) for streamline in newStreamlines]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newBrain = set_number_of_points(brain,101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(619,)"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# newBrain[0].shape\n",
    "trainset[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(npbrain)\n",
    "npbrain = np.array(brain1D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========\n",
    "#   MODEL\n",
    "# ==========\n",
    "\n",
    "# Parameters\n",
    "learning_rate = 0.02\n",
    "training_steps = 70\n",
    "batch_size = 100\n",
    "display_step = 200\n",
    "\n",
    "# Network Parameters\n",
    "seq_max_len = 1000 # Sequence max length\n",
    "n_hidden = 64 # hidden layer num of features\n",
    "n_classes = 2 # linear sequence or not\n",
    "\n",
    "trainset = npbrain[1950:2050]\n",
    "testset = labels[1950:2050]\n",
    "\n",
    "# tf Graph input\n",
    "x = tf.placeholder(\"float\", [None, seq_max_len, 3])\n",
    "y = tf.placeholder(\"float\", [None, n_classes])\n",
    "# A placeholder for indicating each sequence length\n",
    "seqlen = tf.placeholder(tf.int32, [None])\n",
    "\n",
    "# Define weights\n",
    "weights = {\n",
    "    'out': tf.Variable(tf.random_normal([n_hidden, n_classes]))\n",
    "}\n",
    "biases = {\n",
    "    'out': tf.Variable(tf.random_normal([n_classes]))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dynamicRNN(x, seqlen, weights, biases):\n",
    "    # Prepare data shape to match `rnn` function requirements\n",
    "    # Current data input shape: (batch_size, n_steps, n_input)\n",
    "    # Required shape: 'n_steps' tensors list of shape (batch_size, n_input)\n",
    "    \n",
    "    # Unstack to get a list of 'n_steps' tensors of shape (batch_size, n_input)\n",
    "    x = tf.unstack(x, seq_max_len, 1)\n",
    "\n",
    "    # Define a lstm cell with tensorflow\n",
    "    lstm_cell = tf.contrib.rnn.BasicLSTMCell(n_hidden)\n",
    "\n",
    "    # Get lstm cell output, providing 'sequence_length' will perform dynamic\n",
    "    # calculation.\n",
    "    outputs, states = tf.contrib.rnn.static_rnn(lstm_cell, x, dtype=tf.float32,\n",
    "                                sequence_length=seqlen)\n",
    "\n",
    "    # When performing dynamic calculation, we must retrieve the last\n",
    "    # dynamically computed output, i.e., if a sequence length is 10, we need\n",
    "    # to retrieve the 10th output.\n",
    "    # However TensorFlow doesn't support advanced indexing yet, so we build\n",
    "    # a custom op that for each sample in batch size, get its length and\n",
    "    # get the corresponding relevant output.\n",
    "\n",
    "    # 'outputs' is a list of output at every timestep, we pack them in a Tensor\n",
    "    # and change back dimension to [batch_size, n_step, n_input]\n",
    "    outputs = tf.stack(outputs)\n",
    "    outputs = tf.transpose(outputs, [1, 0, 2])\n",
    "\n",
    "    # Hack to build the indexing and retrieve the right output.\n",
    "    batch_size = tf.shape(outputs)[0]\n",
    "    # Start indices for each sample\n",
    "    index = tf.range(0, batch_size) * seq_max_len + (seqlen - 1)\n",
    "    # Indexing\n",
    "    outputs = tf.gather(tf.reshape(outputs, [-1, n_hidden]), index)\n",
    "\n",
    "    # Linear activation, using outputs computed above\n",
    "    return tf.matmul(outputs, weights['out']) + biases['out']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Placeholder', 'Placeholder_1', 'Placeholder_2', 'random_normal/shape', 'random_normal/mean', 'random_normal/stddev', 'random_normal/RandomStandardNormal', 'random_normal/mul', 'random_normal', 'Variable', 'Variable/Assign', 'Variable/read', 'random_normal_1/shape', 'random_normal_1/mean', 'random_normal_1/stddev', 'random_normal_1/RandomStandardNormal', 'random_normal_1/mul', 'random_normal_1', 'Variable_1', 'Variable_1/Assign', 'Variable_1/read', 'IsVariableInitialized', 'IsVariableInitialized_1', 'init']\n",
      "WARNING:tensorflow:From <ipython-input-122-1df78fe636d0>:10: BasicLSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is deprecated, please use tf.nn.rnn_cell.LSTMCell, which supports all the feature this cell currently has. Please replace the existing code with tf.nn.rnn_cell.LSTMCell(name='basic_lstm_cell').\n",
      "WARNING:tensorflow:From <ipython-input-123-3da1ac813a18>:12: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rp7/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:112: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    }
   ],
   "source": [
    "tf_session = keras.backend.get_session()\n",
    "tf_graph = tf.get_default_graph()\n",
    "# tf.reset_default_graph()\n",
    "print([n.name for n in tf.get_default_graph().as_graph_def().node])\n",
    "# tf.contrib.rnn.reset_states()\n",
    "# with tf_session.as_default():\n",
    "#      with tf_graph.as_default():\n",
    "#             tf.reset_default_graph() \n",
    "pred = dynamicRNN(x, seqlen, weights, biases)\n",
    "\n",
    "# Define loss and optimizer\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=pred, labels=y))\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "\n",
    "# Evaluate model\n",
    "correct_pred = tf.equal(tf.argmax(pred,1), tf.argmax(y,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "\n",
    "# Initialize the variables (i.e. assign their default value)\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-124-4f01eda86ce6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;31m# Run optimization op (backprop)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         sess.run(optimizer, feed_dict={x: batch_x, y: batch_y,\n\u001b[0;32m---> 27\u001b[0;31m                                        seqlen: batch_seqlen})\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mdisplay_step\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m             \u001b[0;31m# Calculate batch accuracy & loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    927\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 929\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    930\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1119\u001b[0m             \u001b[0mfeed_handles\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msubfeed_t\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msubfeed_val\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1120\u001b[0m           \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1121\u001b[0;31m             \u001b[0mnp_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubfeed_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msubfeed_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m           if (not is_tensor_handle_feed and\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/numpy/core/numeric.py\u001b[0m in \u001b[0;36masarray\u001b[0;34m(a, dtype, order)\u001b[0m\n\u001b[1;32m    499\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    500\u001b[0m     \"\"\"\n\u001b[0;32m--> 501\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    502\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: setting an array element with a sequence."
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "\n",
    "    # Run the initializer\n",
    "    sess.run(init)\n",
    "\n",
    "    for step in range(1, training_steps+1):\n",
    "#         batch_x, batch_y, batch_seqlen = trainset.next(batch_size)\n",
    "        rangelow = ((step-1)*batch_size)%(trainset.shape[0])\n",
    "        rangehigh = ((step)*batch_size)%(trainset.shape[0])\n",
    "        if(rangehigh==rangelow):\n",
    "            rangehigh=rangehigh-1\n",
    "        if(rangehigh<rangelow):\n",
    "            batch_x = np.append(trainset[rangelow:], trainset[:rangehigh])\n",
    "            batch_y = np.append(testset[rangelow:], testset[:rangehigh])\n",
    "        else:\n",
    "            batch_x = trainset[rangelow:rangehigh]\n",
    "            batch_y = testset[rangelow:rangehigh]\n",
    "        \n",
    "        batch_seqlen = []\n",
    "        for sample in trainset:\n",
    "            batch_seqlen.append(sample.shape[0])\n",
    "\n",
    "#         batch_seqlen = batch_seqlen.tolist()\n",
    "        print(type(batch_seqlen))\n",
    "        # Run optimization op (backprop)\n",
    "        sess.run(optimizer, feed_dict={x: batch_x, y: batch_y,\n",
    "                                       seqlen: batch_seqlen})\n",
    "        if step % display_step == 0 or step == 1:\n",
    "            # Calculate batch accuracy & loss\n",
    "            acc, loss = sess.run([accuracy, cost], feed_dict={x: batch_x, y: batch_y,\n",
    "                                                seqlen: batch_seqlen})\n",
    "            print(\"Step \" + str(step) + \", Minibatch Loss= \" + \\\n",
    "                  \"{:.6f}\".format(loss) + \", Training Accuracy= \" + \\\n",
    "                  \"{:.5f}\".format(acc))\n",
    "\n",
    "    print(\"Optimization Finished!\")\n",
    "\n",
    "    # Calculate accuracy\n",
    "    test_data = testset.data\n",
    "    test_label = testset.labels\n",
    "    test_seqlen = testset.seqlen\n",
    "    print(\"Testing Accuracy:\", \\\n",
    "        sess.run(accuracy, feed_dict={x: test_data, y: test_label,\n",
    "                                      seqlen: test_seqlen}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ToySequenceData(object):\n",
    "    \"\"\" Generate sequence of data with dynamic length.\n",
    "    This class generate samples for training:\n",
    "    - Class 0: linear sequences (i.e. [0, 1, 2, 3,...])\n",
    "    - Class 1: random sequences (i.e. [1, 3, 10, 7,...])\n",
    "\n",
    "    NOTICE:\n",
    "    We have to pad each sequence to reach 'max_seq_len' for TensorFlow\n",
    "    consistency (we cannot feed a numpy array with inconsistent\n",
    "    dimensions). The dynamic calculation will then be perform thanks to\n",
    "    'seqlen' attribute that records every actual sequence length.\n",
    "    \"\"\"\n",
    "    def __init__(self, n_samples=1000, max_seq_len=20, min_seq_len=3,\n",
    "                 max_value=1000):\n",
    "        self.data = []\n",
    "        self.labels = []\n",
    "        self.seqlen = []\n",
    "        for i in range(n_samples):\n",
    "            # Random sequence length\n",
    "            len = np.random.randint(min_seq_len, max_seq_len)\n",
    "            # Monitor sequence length for TensorFlow dynamic calculation\n",
    "            self.seqlen.append(len)\n",
    "            # Add a random or linear int sequence (50% prob)\n",
    "            if np.random.random() < .5:\n",
    "                # Generate a linear sequence\n",
    "                rand_start = np.random.randint(0, max_value - len)\n",
    "                s = [[float(i)/max_value] for i in\n",
    "                     range(rand_start, rand_start + len)]\n",
    "                # Pad sequence for dimension consistency\n",
    "                s += [[0.] for i in range(max_seq_len - len)]\n",
    "                self.data.append(s)\n",
    "                self.labels.append([1., 0.])\n",
    "            else:\n",
    "                # Generate a random sequence\n",
    "                s = [[float(np.random.randint(0, max_value))/max_value]\n",
    "                     for i in range(len)]\n",
    "                # Pad sequence for dimension consistency\n",
    "                s += [[0.] for i in range(max_seq_len - len)]\n",
    "                self.data.append(s)\n",
    "                self.labels.append([0., 1.])\n",
    "        self.batch_id = 0\n",
    "\n",
    "    def next(self, batch_size):\n",
    "        \"\"\" Return a batch of data. When dataset end is reached, start over.\n",
    "        \"\"\"\n",
    "        if self.batch_id == len(self.data):\n",
    "            self.batch_id = 0\n",
    "        batch_data = (self.data[self.batch_id:min(self.batch_id +\n",
    "                                                  batch_size, len(self.data))])\n",
    "        batch_labels = (self.labels[self.batch_id:min(self.batch_id +\n",
    "                                                  batch_size, len(self.data))])\n",
    "        batch_seqlen = (self.seqlen[self.batch_id:min(self.batch_id +\n",
    "                                                  batch_size, len(self.data))])\n",
    "        print(type(batch_seqlen[0]))\n",
    "        self.batch_id = min(self.batch_id + batch_size, len(self.data))\n",
    "        return batch_data, batch_labels, batch_seqlen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr = ToySequenceData(n_samples=1000, max_seq_len=seq_max_len)\n",
    "te = ToySequenceData(n_samples=500, max_seq_len=seq_max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b_x, b_y, b_seqlen = tr.next(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print((b_x))\n",
    "# print(batch_seqlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
