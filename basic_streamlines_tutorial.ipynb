{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from dipy.io.streamline import load_trk\n",
    "from dipy.viz import window, actor\n",
    "import math\n",
    "from nibabel import trackvis as tv\n",
    "from dipy.tracking.streamline import Streamlines\n",
    "from dipy.segment.clustering import QuickBundles\n",
    "from dipy.io.pickles import save_pickle\n",
    "from dipy.data import get_data\n",
    "from dipy.segment.metric import mdf\n",
    "from dipy.segment.metric import AveragePointwiseEuclideanMetric\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "from dipy.io.streamline import load_trk, save_trk\n",
    "import nibabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_streamlines(streamlines): #function to visualize streamlines\n",
    "    \n",
    "    ren = window.Renderer()\n",
    "    ren.add(actor.line(streamlines))\n",
    "    window.show(ren)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_multiple_streamlines(streamline1,streamline2): #function to visualize streamlines\n",
    "    \n",
    "    ren = window.Renderer()\n",
    "    ren.add(actor.line(streamline1))\n",
    "    ren.add(actor.line(streamline2,colors=(0,1,1)))\n",
    "    window.show(ren)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " load brain (tractogram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# brain, b_hr = load_trk(\"brain.trk\")\n",
    "brain=[]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "load Arcuate Fasciculus left fiber bundle (AF_L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bundle, bn_hr = load_trk(\"AF_L.trk\")\n",
    "# brain.append(bundle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = nibabel.streamlines.load(\"SLF_I_right.tck\")\n",
    "save_trk(\"SLF_I_right.trk\",file.streamlines, np.eye(4))\n",
    "bundle, bn_hr = load_trk(\"SLF_I_right.trk\")\n",
    "brain.append(bundle[:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = nibabel.streamlines.load(\"OR_left.tck\")\n",
    "save_trk(\"OR_left.trk\",file.streamlines, np.eye(4))\n",
    "bundle, bn_hr = load_trk(\"OR_left.trk\")\n",
    "brain.append(bundle[:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = nibabel.streamlines.load(\"ICP_left.tck\")\n",
    "save_trk(\"ICP_left.trk\",file.streamlines, np.eye(4))\n",
    "bundle, bn_hr = load_trk(\"ICP_left.trk\")\n",
    "brain.append(bundle[:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = nibabel.streamlines.load(\"FX_right.tck\")\n",
    "save_trk(\"FX_right.trk\",file.streamlines, np.eye(4))\n",
    "bundle, bn_hr = load_trk(\"FX_right.trk\")\n",
    "brain.append(bundle[:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cst, bn_hr = load_trk(\"CST_recognized.trk\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "let's visualize them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "need at least one array to concatenate",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-7d3554ed5247>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#show_streamlines(brain)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mshow_multiple_streamlines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1953\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m1954\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1950\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m81\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m1950\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m82\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-3-b534f7355731>\u001b[0m in \u001b[0;36mshow_multiple_streamlines\u001b[0;34m(streamline1, streamline2)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mren\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwindow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRenderer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mren\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstreamline1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mren\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstreamline2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcolors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mwindow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mren\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/FiberBundles/dipy/dipy/viz/actor.py\u001b[0m in \u001b[0;36mline\u001b[0;34m(lines, colors, opacity, linewidth, spline_subdiv, lod, lod_points, lod_points_size, lookup_colormap)\u001b[0m\n\u001b[1;32m    549\u001b[0m     \"\"\"\n\u001b[1;32m    550\u001b[0m     \u001b[0;31m# Poly data with lines and colors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 551\u001b[0;31m     \u001b[0mpoly_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_colormap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlines_to_vtk_polydata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlines\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    552\u001b[0m     \u001b[0mnext_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpoly_data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    553\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/FiberBundles/dipy/dipy/viz/utils.py\u001b[0m in \u001b[0;36mlines_to_vtk_polydata\u001b[0;34m(lines, colors)\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m     \u001b[0;31m# Get the 3d points_array\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 155\u001b[0;31m     \u001b[0mpoints_array\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlines\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    156\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m     \u001b[0mnb_lines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlines\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/numpy/core/shape_base.py\u001b[0m in \u001b[0;36mvstack\u001b[0;34m(tup)\u001b[0m\n\u001b[1;32m    232\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m     \"\"\"\n\u001b[0;32m--> 234\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_nx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0matleast_2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_m\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_m\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtup\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mhstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: need at least one array to concatenate"
     ]
    }
   ],
   "source": [
    "# first brain\n",
    "\n",
    "#show_streamlines(brain)\n",
    "show_multiple_streamlines(brain[1953:1954], brain[1950+81:1950+82])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rp7/anaconda3/lib/python3.6/site-packages/vtk/util/numpy_support.py:137: FutureWarning: Conversion of the second argument of issubdtype from `complex` to `np.complexfloating` is deprecated. In future, it will be treated as `np.complex128 == np.dtype(complex).type`.\n",
      "  assert not numpy.issubdtype(z.dtype, complex), \\\n"
     ]
    }
   ],
   "source": [
    "# now bundle\n",
    "brain = np.array(brain).flatten()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_streamlines(brain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "331"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(bundle[0].shape)\n",
    "len(bundle[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get labels\n",
    "\n",
    "def getLabels(brain, bundle):\n",
    "    labels = np.zeros(len(brain))\n",
    "    npbrain = np.array(brain)\n",
    "    for i in range(len(bundle)):\n",
    "        for j in range(len(brain)):\n",
    "            if((npbrain[j].shape[0]==bundle[i].shape[0])):\n",
    "    #         print(i,j)\n",
    "                if np.allclose(npbrain[j], bundle[i]):\n",
    "                    labels[j] = 1\n",
    "                    break\n",
    "        if(i%100==0):\n",
    "            print(i,end=\" \")\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 100 200 300 400 500 600 700 800 900 1000 1100 1200 1300 1400 1500 1600 1700 1800 1900 "
     ]
    }
   ],
   "source": [
    "labels = np.zeros(len(brain))\n",
    "l = getLabels(brain, brain[:50])\n",
    "labels[l==l] = 0\n",
    "l = getLabels(brain, brain[50:100])\n",
    "labels[l==l] = 1\n",
    "l = getLabels(brain, brain[100:150])\n",
    "labels[l==l] = 2\n",
    "l = getLabels(brain, brain[150:200])\n",
    "labels[l==l] = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.zeros(len(brain))\n",
    "labels[:50] = 0\n",
    "labels[50:100] = 1\n",
    "labels[100:150] = 2\n",
    "labels[150:] = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find Frechet distance\n",
    "# From : https://gist.github.com/MaxBareiss/ba2f9441d9455b56fbc9\n",
    "\n",
    "# Euclidean distance.\n",
    "def euc_dist(pt1,pt2):\n",
    "    return math.sqrt((pt2[0]-pt1[0])*(pt2[0]-pt1[0])+(pt2[1]-pt1[1])*(pt2[1]-pt1[1]))\n",
    "\n",
    "def _c(ca,i,j,P,Q):\n",
    "    if ca[i,j] > -1:\n",
    "        return ca[i,j]\n",
    "    elif i == 0 and j == 0:\n",
    "        ca[i,j] = euc_dist(P[0],Q[0])\n",
    "    elif i > 0 and j == 0:\n",
    "        ca[i,j] = max(_c(ca,i-1,0,P,Q),euc_dist(P[i],Q[0]))\n",
    "    elif i == 0 and j > 0:\n",
    "        ca[i,j] = max(_c(ca,0,j-1,P,Q),euc_dist(P[0],Q[j]))\n",
    "    elif i > 0 and j > 0:\n",
    "        ca[i,j] = max(min(_c(ca,i-1,j,P,Q),_c(ca,i-1,j-1,P,Q),_c(ca,i,j-1,P,Q)),euc_dist(P[i],Q[j]))\n",
    "    else:\n",
    "        ca[i,j] = float(\"inf\")\n",
    "    return ca[i,j]\n",
    "\n",
    "\"\"\" Computes the discrete frechet distance between two polygonal lines\n",
    "Algorithm: http://www.kr.tuwien.ac.at/staff/eiter/et-archive/cdtr9464.pdf\n",
    "P and Q are arrays of 2-element arrays (points)\n",
    "\"\"\"\n",
    "def frechetDist(P,Q):\n",
    "    ca = np.ones((len(P),len(Q)))\n",
    "    ca = np.multiply(ca,-1)\n",
    "    return _c(ca,len(P)-1,len(Q)-1,P,Q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fast Dynamic time warping\n",
    "# From: https://github.com/slaypni/fastdtw\n",
    "\n",
    "import numpy as np\n",
    "from fastdtw import fastdtw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dipy.align.streamlinear import BundleMinDistanceMetric\n",
    "from dipy.align.streamlinear import set_number_of_points\n",
    "# BundleMinDistanceMetric().distance(cBrain3D[0],cBrain3D[1])\n",
    "\n",
    "def bmd(a,b):\n",
    "    static = set_number_of_points(a, len(a))\n",
    "    moving = set_number_of_points(b, len(b))\n",
    "    BMD = BundleMinDistanceMetric()\n",
    "    BMD.setup(static, moving)\n",
    "    x0 = np.array([0, 0, 0, 0, 0, 0, 1., 1., 1, 0, 0, 0])  # affine\n",
    "    bmd_value = BMD.distance(x0.tolist())\n",
    "    return bmd_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bmd(brain3D[0],brain3D[7])\n",
    "# brain3D[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get distance between 2 curves\n",
    "from scipy.spatial.distance import euclidean\n",
    "\n",
    "def distanceBetweenCurves(c1, c2, algo='fastdtw'):\n",
    "    if algo=='fastdtw':\n",
    "        distance, path = fastdtw(c1,c2, radius = 1, dist = euclidean) # check out the 'radius' parameter to tune the distance\n",
    "        return distance\n",
    "    elif algo=='frechet':\n",
    "        return frechetDist(c1,c2)\n",
    "    elif algo=='bmd':\n",
    "        return bmd(c1,c2)\n",
    "    elif algo=='mdf':\n",
    "        return mdf(c1,c2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "def project2D(streamline):\n",
    "    pca = PCA(n_components=2)\n",
    "    newBundle = pca.fit_transform(streamline)\n",
    "#     newStreamline = Streamlines([(np.hstack((newBundle,np.zeros((newBundle.shape[0])).reshape((-1,1)))))])\n",
    "    newStreamline = Streamlines([newBundle])\n",
    "    return newStreamline, pca.components_, pca.singular_values_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(pca.explained_variance_ratio_) \n",
    "# print(pca.singular_values_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# st = Streamlines([newBundle])\n",
    "def convertToAngles(streamline2D):\n",
    "    streamline2D = np.array(streamline2D)\n",
    "#     print((streamline2D))\n",
    "    angles = np.zeros(streamline2D.shape[0])\n",
    "    angles[0] = 1\n",
    "#     print(streamline2D.shape)\n",
    "    # handle the direction of start\n",
    "#     print(streamline2D.shape)\n",
    "    for point in range(1,streamline2D.shape[0]):\n",
    "#         print(point)\n",
    "        diff = streamline2D[point] - streamline2D[point-1]\n",
    "#         print(streamline2D[point], streamline2D[point-1])\n",
    "        if(diff[0]==0):\n",
    "            angles[point] = angles[point-1]\n",
    "        else:\n",
    "            angles[point] = math.degrees(math.atan(diff[1]/diff[0]))\n",
    "    return angles\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# center the data\n",
    "def centerData(data):\n",
    "    for i in range(len(data)):\n",
    "        mean = np.mean(data[i],axis=0)\n",
    "        data[i] = data[i]-mean\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDataLD(bundle):\n",
    "    data2D = []\n",
    "    angularData = []\n",
    "    eigenValues = []\n",
    "    eigenVecs = []\n",
    "    for index in range(len(bundle)):\n",
    "        newStreamline, vecs, singVal = project2D(np.array(bundle[index]))\n",
    "        data2D.append(newStreamline[0][:,:2])\n",
    "        eigenValues.append(singVal)\n",
    "        eigenVecs.append(vecs)\n",
    "        # append these values to store them \n",
    "        streamlineAsAngle = convertToAngles(newStreamline[0])\n",
    "#         print(streamlineAsAngle)\n",
    "        angularData.append(streamlineAsAngle)\n",
    "    \n",
    "    return angularData, data2D, eigenVecs, eigenValues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cBrain = centerData(np.array(brain))\n",
    "brain1D, brain2D, eigenVecs, eigenValues = getDataLD(cBrain)\n",
    "brain3D = np.array(cBrain).tolist()\n",
    "# show_multiple_streamlines(newStreamline,bundle[0:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From https://www.geeksforgeeks.org/program-to-find-equation-of-a-plane-passing-through-3-points/\n",
    "# get equation of plane from 3 points\n",
    "def getPlaneEquation(p1, p2, p3):    \n",
    "    a1 = p2[0] - p1[0] \n",
    "    b1 = p2[1] - p1[1] \n",
    "    c1 = p2[2] - p1[2] \n",
    "    a2 = p3[0] - p1[0] \n",
    "    b2 = p3[1] - p1[1] \n",
    "    c2 = p3[2] - p1[2]\n",
    "    a = b1 * c2 - b2 * c1 \n",
    "    b = a2 * c1 - a1 * c2 \n",
    "    c = a1 * b2 - b1 * a2 \n",
    "    d = (- a * p1[0] - b * p1[1] - c * p1[2]) \n",
    "    norm = np.sqrt(a**2+b**2+c**2)\n",
    "    return a/norm,b/norm,c/norm,d/norm\n",
    "#     print \"equation of plane is \", \n",
    "#     print a, \"x +\", \n",
    "#     print b, \"y +\", \n",
    "#     print c, \"z +\", \n",
    "#     print d, \"= 0.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# brain data in a particular plane but in 3D space\n",
    "x2DBrain3D = [(np.dot(eigenVecs[i].T, stream.T)).T for i, stream in enumerate(brain2D)]\n",
    "# (eigenVecs[0]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x2DBrain3D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_multiple_streamlines(x2DBrain3D[65:66],brain3D[65:66])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9858762976317351,\n",
       " 0.0679287596567005,\n",
       " 0.15308040168305262,\n",
       " 0.3605892652705367)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getPlaneEquation(x2DBrain3D[4][5], x2DBrain3D[4][6], x2DBrain3D[4][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rodriguesRotation(axis, vector, angle):\n",
    "    # axis should be a unit vector\n",
    "    return vector*np.cos(angle) + (np.cross(axis, vector))*np.sin(angle) + axis*(np.dot(axis,vector))*(1-np.cos(angle))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.0000000e+00, 0.0000000e+00, 2.4492936e-16])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rodriguesRotation(np.array([0,1,0]), np.array([1,0,0]), 2*np.pi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "atheta = 0\n",
    "ztheta = 0\n",
    "subSegments = 7 # using odd value to prevent redunduncy in the discrete planes\n",
    "subAngles = np.pi/subSegments\n",
    "noOfPlanes = subSegments*subSegments\n",
    "discretePlanes = []\n",
    "for a in range(subSegments):\n",
    "    vec = np.array([np.cos(atheta+(a*subAngles)), np.sin(atheta+(a*subAngles)), 0])\n",
    "    axis = np.array([np.cos((np.pi/2)+atheta+(a*subAngles)), np.sin((np.pi/2)+atheta+(a*subAngles)), 0])\n",
    "    for z in range(subSegments):\n",
    "        discretePlanes.append(rodriguesRotation(axis, vec, ztheta+(z*subAngles)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "discretePlanes = np.array(discretePlanes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (brain3D[0]).shape\n",
    "# temp = Streamlines([(np.hstack((brain2D[3],np.zeros((brain2D[3].shape[0])).reshape((-1,1)))))])\n",
    "# show_multiple_streamlines(temp,tempStream)\n",
    "# print(len(brain1D),len(brain2D),len(brain3D))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 2 is out of bounds for axis 0 with size 2",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-40-ef476f18b32e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meigenVecs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0meigenVecs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m: index 2 is out of bounds for axis 0 with size 2"
     ]
    }
   ],
   "source": [
    "np.dot((eigenVecs[3][1]), (eigenVecs[3][2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27224.70919387607"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distanceBetweenCurves(brain3D[3], brain3D[81], 'fastdtw')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 "
     ]
    }
   ],
   "source": [
    "# create covariance matrix\n",
    "\n",
    "cov = np.zeros((len(brain3D), len(brain3D)))\n",
    "for i in range(len(brain3D)):\n",
    "    for j in range(len(brain3D)):\n",
    "        cov[i][j] = distanceBetweenCurves(brain3D[i], brain3D[j], 'fastdtw')\n",
    "    print(i, end=\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store the covariance matrix variable to disk\n",
    "\n",
    "# Save\n",
    "# with open('covarianceDTW3D.pkl', 'wb') as f:\n",
    "#     pickle.dump(cov, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve\n",
    "cov = []\n",
    "with open('covarianceDTW3D.pkl', 'rb') as f:\n",
    "    cov = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 200)"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cov.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0xb5a364358>"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib qt\n",
    "plt.imshow(cov)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2 µs, sys: 1 µs, total: 3 µs\n",
      "Wall time: 14.1 µs\n"
     ]
    }
   ],
   "source": [
    "# get centroids for the bundles\n",
    "\n",
    "%time\n",
    "def getCentroids(streamlines, noOfCentroids, pointsInCentroid=400):\n",
    "    streamlines = [set_number_of_points(streamline, nb_points=pointsInCentroid) for streamline in streamlines]\n",
    "    thresh=1\n",
    "    qb = QuickBundles(threshold=thresh, metric=AveragePointwiseEuclideanMetric())\n",
    "    clusters = qb.cluster(streamlines)\n",
    "    length = len(clusters.centroids)\n",
    "    prev = 0\n",
    "    flag=False\n",
    "    while(length!=noOfCentroids):\n",
    "        if(length>noOfCentroids):\n",
    "            if flag:\n",
    "                temp = thresh\n",
    "                thresh= thresh + (thresh-prev)/2.0\n",
    "                prev = temp\n",
    "            else:\n",
    "                prev=thresh\n",
    "                thresh *= 2.0\n",
    "        else:\n",
    "            temp = thresh\n",
    "            thresh = prev+(thresh-prev)/2.0\n",
    "            flag = True\n",
    "        qb = QuickBundles(threshold=thresh, metric=AveragePointwiseEuclideanMetric())\n",
    "        clusters = qb.cluster(streamlines)\n",
    "        length = len(clusters)\n",
    "    return np.array(clusters.centroids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2 µs, sys: 0 ns, total: 2 µs\n",
      "Wall time: 5.01 µs\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "def getAllCentroids(brainData, labels, noOfBundles, noOfCentroids=3):\n",
    "    centroids = []\n",
    "    for n in range(noOfBundles):\n",
    "        print(n)\n",
    "        if n==0:\n",
    "            c = getCentroids(brainData[labels==n], noOfCentroids)\n",
    "            centroids = c.reshape((1,)+c.shape)\n",
    "        else:\n",
    "            centroids = np.vstack((centroids, getCentroids(brainData[labels==n], noOfCentroids).reshape((1,)+c.shape)))\n",
    "    return centroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1., 2., 3.])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(np.unique(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "# shape = (no of bundles, no of centroids in each bundle, no of points in each centroid, dimensions of the points)\n",
    "centroidMat = getAllCentroids(np.array(brain3D),labels, len(np.unique(labels)))\n",
    "\n",
    "# Save\n",
    "with open('centroidMat.pkl', 'wb') as f:\n",
    "    pickle.dump(centroidMat, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve\n",
    "with open('centroidMat.pkl', 'rb') as f:\n",
    "    centroidMat = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 3, 400, 3)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "centroidMat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get distance of a streamline from all the centroids\n",
    "def getDistToCentroids(streamline):\n",
    "    global centroidMat\n",
    "    distMat = np.zeros((centroidMat.shape[0], centroidMat.shape[1]))\n",
    "    for i in range(distMat.shape[0]):\n",
    "        for j in range(distMat.shape[1]):\n",
    "            distMat[i][j] = distanceBetweenCurves(centroidMat[i][j], streamline, 'fastdtw')\n",
    "    return distMat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get probability of getting a bundle given a streamline(shape)\n",
    "def pB_S(streamline, metric='min'):\n",
    "    distMat = getDistToCentroids(streamline)\n",
    "    if metric=='min':\n",
    "        distToBundles = np.min(distMat, axis=1)\n",
    "    elif metric=='avg':\n",
    "        distToBundles = np.mean(distMat, axis=1)\n",
    "    \n",
    "    probabilities = 1/distToBundles\n",
    "    probabilities /= np.sum(probabilities)\n",
    "    return probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.75134319 0.10062288 0.0891755  0.05885844]\n",
      "[0.53317047 0.17721768 0.16244019 0.12717166]\n",
      "[0.11144387 0.41299634 0.1763508  0.29920899]\n",
      "[0.11832459 0.41054582 0.17915182 0.29197777]\n",
      "[0.11694108 0.42199461 0.17256388 0.28850043]\n",
      "[0.118765   0.42439587 0.17144236 0.28539677]\n",
      "[0.58466736 0.1242622  0.19696202 0.09410842]\n",
      "[0.67460314 0.12463348 0.12408988 0.07667351]\n",
      "[0.08287853 0.51950108 0.14236462 0.25525576]\n",
      "[0.09670777 0.47795795 0.15851169 0.26682259]\n",
      "[0.6140183  0.15217763 0.13915601 0.09464805]\n",
      "[0.69320814 0.11693956 0.11698009 0.07287221]\n",
      "[0.11226416 0.43948818 0.17159344 0.27665422]\n",
      "[0.67043385 0.11211835 0.13548577 0.08196203]\n",
      "[0.09598884 0.30317022 0.16676709 0.43407385]\n",
      "[0.11783129 0.41050737 0.17923861 0.29242273]\n",
      "[0.13873674 0.25496204 0.23768382 0.3686174 ]\n",
      "[0.54694623 0.17413954 0.15987942 0.11903481]\n",
      "[0.66928853 0.12642303 0.11731032 0.08697812]\n",
      "[0.53555149 0.17365244 0.17255625 0.11823982]\n",
      "[0.64278108 0.13957939 0.13057071 0.08706881]\n",
      "[0.09516657 0.35173957 0.16599368 0.38710018]\n",
      "[0.54041272 0.16993445 0.17406568 0.11558715]\n",
      "[0.74546686 0.08389862 0.10583468 0.06479984]\n",
      "[0.10729222 0.38162892 0.16803267 0.34304619]\n",
      "[0.09228655 0.27623421 0.16044529 0.47103394]\n",
      "[0.12693072 0.3570685  0.20406581 0.31193497]\n",
      "[0.12804472 0.35364739 0.20415653 0.31415137]\n",
      "[0.12323865 0.40644971 0.18642649 0.28388515]\n",
      "[0.12013697 0.42076745 0.17929364 0.27980194]\n",
      "[0.81602627 0.07577163 0.06610334 0.04209876]\n",
      "[0.71937589 0.09729886 0.1111246  0.07220065]\n",
      "[0.14193533 0.2897394  0.22768449 0.34064078]\n",
      "[0.10256809 0.49357187 0.15397144 0.24988861]\n",
      "[0.67353075 0.13908458 0.11187165 0.07551302]\n",
      "[0.11173798 0.4603726  0.16719048 0.26069894]\n",
      "[0.08680532 0.55582802 0.13344903 0.22391763]\n",
      "[0.59916712 0.14238529 0.16303163 0.09541597]\n",
      "[0.12782831 0.38550457 0.18475477 0.30191235]\n",
      "[0.13183855 0.28984673 0.19660242 0.3817123 ]\n",
      "[0.5603572  0.13657396 0.18701765 0.11605118]\n",
      "[0.13015201 0.29127018 0.20885255 0.36972526]\n",
      "[0.13410957 0.39808803 0.18936701 0.27843539]\n",
      "[0.65176458 0.13795944 0.12430035 0.08597563]\n",
      "[0.08733766 0.37323653 0.15127122 0.38815459]\n",
      "[0.78876437 0.08697129 0.07651711 0.04774724]\n",
      "[0.09586569 0.4798601  0.15361348 0.27066073]\n",
      "[0.6023168  0.13179453 0.15824635 0.10764232]\n",
      "[0.67569026 0.1379207  0.11166319 0.07472586]\n",
      "[0.769343   0.09578185 0.08237048 0.05250467]\n",
      "[0.0717996  0.45345175 0.1387158  0.33603285]\n",
      "[0.08689495 0.54827705 0.13743698 0.22739102]\n",
      "[0.0761653  0.6163809  0.12192343 0.18553036]\n",
      "[0.4040857  0.23020726 0.24123563 0.12447141]\n",
      "[0.08879375 0.56988885 0.13588597 0.20543143]\n",
      "[0.37935299 0.22690192 0.25700452 0.13674057]\n",
      "[0.08940074 0.66168869 0.10016832 0.14874225]\n",
      "[0.4166472  0.22905465 0.22601717 0.12828098]\n",
      "[0.0811711  0.51137844 0.13215454 0.27529592]\n",
      "[0.06711116 0.62466853 0.11339478 0.19482554]\n",
      "[0.42623295 0.2240692  0.2089405  0.14075734]\n",
      "[0.0689078  0.62215007 0.11678954 0.19215258]\n",
      "[0.08656517 0.47155787 0.14082435 0.30105261]\n",
      "[0.08229175 0.58296949 0.13872127 0.19601749]\n",
      "[0.38942165 0.23448503 0.23180564 0.14428768]\n",
      "[0.08883302 0.51795252 0.15381346 0.23940101]\n",
      "[0.49884063 0.17489557 0.20754157 0.11872223]\n",
      "[0.10086073 0.53260194 0.14879798 0.21773936]\n",
      "[0.06815861 0.63697361 0.11222704 0.18264074]\n",
      "[0.4667149  0.20921544 0.19940266 0.12466699]\n",
      "[0.40851045 0.22602557 0.22885714 0.13660684]\n",
      "[0.06588552 0.63620438 0.10659013 0.19131997]\n",
      "[0.40409009 0.24124188 0.22547052 0.12919751]\n",
      "[0.39340979 0.23600907 0.24433807 0.12624307]\n",
      "[0.34952019 0.23580096 0.28063123 0.13404761]\n",
      "[0.08204428 0.57184967 0.12828977 0.21781627]\n",
      "[0.05594138 0.67517588 0.09314477 0.17573797]\n",
      "[0.07563028 0.54588268 0.122506   0.25598103]\n",
      "[0.07813802 0.74649937 0.08343876 0.09192386]\n",
      "[0.44937766 0.21703205 0.20607317 0.12751711]\n",
      "[0.35424158 0.24555428 0.26809551 0.13210863]\n",
      "[0.45556738 0.21720137 0.20411595 0.1231153 ]\n",
      "[0.07705676 0.5644422  0.12825302 0.23024802]\n",
      "[0.09026577 0.55243876 0.15054489 0.20675057]\n",
      "[0.08724034 0.54878847 0.14833176 0.21563943]\n",
      "[0.06180947 0.80629234 0.06240372 0.06949446]\n",
      "[0.33383798 0.22322483 0.30873918 0.13419802]\n",
      "[0.06553011 0.4664666  0.12556687 0.34243642]\n",
      "[0.09468967 0.50172617 0.16174168 0.24184248]\n",
      "[0.3465994  0.22620298 0.29144031 0.13575732]\n",
      "[0.3051841  0.23959302 0.30771914 0.14750373]\n",
      "[0.47108598 0.2027413  0.20481807 0.12135465]\n",
      "[0.08074989 0.5858239  0.12519627 0.20822994]\n",
      "[0.4182654  0.2268132  0.21249635 0.14242504]\n",
      "[0.07078715 0.60691833 0.11227323 0.21002129]\n",
      "[0.48277213 0.19657883 0.20120924 0.1194398 ]\n",
      "[0.41806771 0.22257462 0.21528597 0.1440717 ]\n",
      "[0.34235333 0.22003805 0.30274598 0.13486264]\n",
      "[0.3266397  0.2311635  0.30409956 0.13809724]\n",
      "[0.36321486 0.27223045 0.22126809 0.14328661]\n",
      "[0.14415579 0.12129364 0.62560056 0.10895001]\n",
      "[0.16240526 0.11839122 0.61981387 0.09938966]\n",
      "[0.13182584 0.16775035 0.22436985 0.47605396]\n",
      "[0.14839416 0.1244118  0.60085974 0.12633431]\n",
      "[0.16046728 0.15836802 0.57551692 0.10564777]\n",
      "[0.14008002 0.2739716  0.2636633  0.32228508]\n",
      "[0.09502765 0.165843   0.20592223 0.53320713]\n",
      "[0.10120141 0.26672111 0.22410255 0.40797494]\n",
      "[0.13232823 0.1659739  0.22446218 0.47723569]\n",
      "[0.19487428 0.12852001 0.50724361 0.1693621 ]\n",
      "[0.1414898  0.13608019 0.59145818 0.13097182]\n",
      "[0.18316809 0.16418193 0.44601732 0.20663267]\n",
      "[0.11003373 0.10733853 0.69398982 0.08863792]\n",
      "[0.15802488 0.22984073 0.27921008 0.33292432]\n",
      "[0.10248378 0.09881291 0.71693349 0.08176982]\n",
      "[0.17543116 0.16397773 0.46412005 0.19647105]\n",
      "[0.18938503 0.17791882 0.51163904 0.12105711]\n",
      "[0.16830512 0.16002282 0.56907574 0.10259632]\n",
      "[0.14072269 0.12145714 0.62487889 0.11294127]\n",
      "[0.10021514 0.18300862 0.21267043 0.50410581]\n",
      "[0.15455481 0.14817696 0.2288783  0.46838994]\n",
      "[0.1963212  0.15988962 0.53898786 0.10480132]\n",
      "[0.16197315 0.21052918 0.28823398 0.33926368]\n",
      "[0.19272868 0.11409372 0.55884552 0.13433209]\n",
      "[0.14523853 0.12184705 0.61229929 0.12061512]\n",
      "[0.09346784 0.20100138 0.20653242 0.49899836]\n",
      "[0.07654514 0.13036478 0.22800434 0.56508574]\n",
      "[0.10082156 0.23372952 0.22243976 0.44300916]\n",
      "[0.22786092 0.19948603 0.44414205 0.128511  ]\n",
      "[0.13854495 0.15137747 0.20946061 0.50061696]\n",
      "[0.13867298 0.11007257 0.66581613 0.08543832]\n",
      "[0.12593462 0.24508878 0.26908479 0.3598918 ]\n",
      "[0.15090626 0.23734611 0.29100642 0.32074122]\n",
      "[0.11301688 0.27363774 0.24604951 0.36729587]\n",
      "[0.15919188 0.24688005 0.27551652 0.31841154]\n",
      "[0.1961109  0.1524176  0.27290535 0.37856615]\n",
      "[0.09661364 0.09227912 0.73550515 0.0756021 ]\n",
      "[0.15043417 0.25831918 0.27187794 0.31936871]\n",
      "[0.1005051  0.26321368 0.22283405 0.41344716]\n",
      "[0.19312998 0.12553502 0.53346503 0.14786996]\n",
      "[0.29903962 0.15565116 0.41421513 0.13109409]\n",
      "[0.26394903 0.21939361 0.38503083 0.13162653]\n",
      "[0.1100844  0.10856381 0.69724823 0.08410356]\n",
      "[0.21555259 0.15862948 0.51898399 0.10683394]\n",
      "[0.08500907 0.07939248 0.7694999  0.06609855]\n",
      "[0.1771488  0.15840406 0.475579   0.18886815]\n",
      "[0.09416195 0.19475583 0.21590243 0.49517979]\n",
      "[0.00408188 0.00391329 0.98568517 0.00631966]\n",
      "[0.15222017 0.12718669 0.60201635 0.1185768 ]\n",
      "[0.11233214 0.30018744 0.23338774 0.35409268]\n",
      "[0.01270192 0.04008219 0.02760178 0.91961411]\n",
      "[0.38604976 0.19161884 0.26107504 0.16125635]\n",
      "[0.37014129 0.20489902 0.26266993 0.16228976]\n",
      "[0.17722978 0.13754679 0.57843148 0.10679195]\n",
      "[0.02841863 0.08483664 0.06389299 0.82285174]\n",
      "[0.02087347 0.06657278 0.0459439  0.86660985]\n",
      "[0.02318741 0.06913071 0.05111627 0.85656561]\n",
      "[0.38342998 0.18908187 0.26975497 0.15773318]\n",
      "[0.37712152 0.19609857 0.27124172 0.15553819]\n",
      "[0.05517031 0.13111072 0.1255829  0.68813608]\n",
      "[0.03822343 0.13572757 0.07942529 0.74662371]\n",
      "[0.16846268 0.13459889 0.59279667 0.10414176]\n",
      "[0.00480433 0.01404728 0.01076142 0.97038698]\n",
      "[0.3702191  0.20329435 0.26908868 0.15739787]\n",
      "[0.35492674 0.21415698 0.27884467 0.15207161]\n",
      "[0.00632694 0.01811062 0.01422907 0.96133336]\n",
      "[0.3802974  0.19346042 0.27069316 0.15554902]\n",
      "[0.02241919 0.07555477 0.04773298 0.85429306]\n",
      "[0.17419073 0.13484665 0.58658557 0.10437705]\n",
      "[0.38554029 0.1907653  0.26107401 0.1626204 ]\n",
      "[0.16721798 0.12904293 0.60625845 0.09748065]\n",
      "[0.37086288 0.2039851  0.26896709 0.15618493]\n",
      "[0.01315916 0.04158918 0.02891393 0.91633773]\n",
      "[0.38688333 0.1898407  0.26059282 0.16268315]\n",
      "[0.37791191 0.1989608  0.26426708 0.1588602 ]\n",
      "[0.36201479 0.20928626 0.27160376 0.1570952 ]\n",
      "[0.37934651 0.19771202 0.26328615 0.15965531]\n",
      "[0.37739331 0.19812161 0.26028737 0.16419771]\n",
      "[0.36744832 0.20443085 0.26820324 0.15991759]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0255236  0.08313855 0.05590694 0.83543091]\n",
      "[0.37792632 0.20188044 0.2591792  0.16101404]\n",
      "[0.38610603 0.19107409 0.26095128 0.1618686 ]\n",
      "[0.37447553 0.19399661 0.2766444  0.15488346]\n",
      "[0.03295691 0.09901014 0.07433116 0.79370179]\n",
      "[0.00347084 0.01100555 0.00757659 0.97794702]\n",
      "[0.02846297 0.08521933 0.06277302 0.82354468]\n",
      "[0.02398623 0.0758253  0.05176602 0.84842246]\n",
      "[0.38006589 0.19655588 0.25993462 0.16344361]\n",
      "[0.37103552 0.20307105 0.26864712 0.15724631]\n",
      "[0.01289393 0.03981532 0.02853331 0.91875744]\n",
      "[0.37512871 0.20143376 0.2603664  0.16307112]\n",
      "[0.35284633 0.21613125 0.27898049 0.15204193]\n",
      "[0.01233935 0.03651166 0.0274156  0.92373338]\n",
      "[0.02240334 0.06686921 0.05001063 0.86071682]\n",
      "[0.00984311 0.01402483 0.02183672 0.95429534]\n",
      "[0.3843752  0.19326342 0.26135658 0.16100481]\n",
      "[0.3755362  0.2013591  0.2605707  0.16253401]\n",
      "[0.02655418 0.09107233 0.05599779 0.8263757 ]\n",
      "[0.38004643 0.19737157 0.26255079 0.16003121]\n",
      "[0.36740709 0.18376189 0.27222059 0.17661043]\n"
     ]
    }
   ],
   "source": [
    "count=[]\n",
    "predictions1 = []\n",
    "predictions2 = []\n",
    "predictions3 = []\n",
    "predictions0 = []\n",
    "for i in range(200):\n",
    "    cls = ((pB_S(brain3D[i])))\n",
    "    if np.argmax(cls)==0:\n",
    "        predictions0.append(brain3D[i])\n",
    "    if np.argmax(cls)==1:\n",
    "        predictions1.append(brain3D[i])\n",
    "    if np.argmax(cls)==2:\n",
    "        predictions2.append(brain3D[i])\n",
    "    if np.argmax(cls)==3:\n",
    "        predictions3.append(brain3D[i])\n",
    "    count.append(np.argmax(cls))\n",
    "    print(cls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rp7/anaconda3/lib/python3.6/site-packages/vtk/util/numpy_support.py:137: FutureWarning: Conversion of the second argument of issubdtype from `complex` to `np.complexfloating` is deprecated. In future, it will be treated as `np.complex128 == np.dtype(complex).type`.\n",
      "  assert not numpy.issubdtype(z.dtype, complex), \\\n"
     ]
    }
   ],
   "source": [
    "show_streamlines(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.485"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count = np.array(count)\n",
    "(np.sum(count[:50]==0) + np.sum(count[50:100]==1) + np.sum(count[100:150]==2) + np.sum(count[150:]==3))/200\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# probability of a centroid given a particular streamline(shape)\n",
    "# dimensions: (no of bundles, no of centroids)\n",
    "def pC_S(streamline):\n",
    "    dist = 1/getDistToCentroids(streamline)\n",
    "    return dist/np.sum(dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# centroidMat.reshape((2,3)).shape\n",
    "# (np.dot(eigenVecs[i].T, stream.T)).T\n",
    "len(discretePlanes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get angle between 2 planes\n",
    "def dihedralAngle(a, b):\n",
    "    temp =  np.arccos((np.dot(a,b))/(np.linalg.norm(a)*np.linalg.norm(b)))\n",
    "    if temp>10000:\n",
    "        print(a,b)\n",
    "    return temp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dimensions: (total number of centroids, number of discrete planes)\n",
    "def pP_C():\n",
    "    noOfPlanes = len(discretePlanes)\n",
    "    probabilities = np.zeros((centroidMat.shape[0]*centroidMat.shape[1], noOfPlanes))\n",
    "    for i in range(centroidMat.shape[0]):\n",
    "        for j in range(centroidMat.shape[1]):\n",
    "            cent, evecs, evalue = project2D(centerData(centroidMat[i][j]))\n",
    "            PCAedCentroid = (np.dot(evecs.T, np.array(cent[0]).T)).T\n",
    "            a,b,c,d = getPlaneEquation(PCAedCentroid[0],PCAedCentroid[1],PCAedCentroid[2])\n",
    "            for k in range(noOfPlanes):\n",
    "                probabilities[centroidMat.shape[1]*i+j][k] = dihedralAngle(np.array([a,b,c]), discretePlanes[k])\n",
    "            \n",
    "    probabilities = 1.0/probabilities\n",
    "    probabilities /= np.sum(probabilities, axis=1).reshape((-1,1))\n",
    "    return probabilities\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8077343472643393"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dihedralAngle(np.array([-0.5775682004691819, -0.5773971386380066, -0.5770853646553805]), discretePlanes[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "pPC = pP_C()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 3, 400, 3)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "centroidMat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dimensions: (number of discrete planes, no of bundles)\n",
    "def pB_P(pPC, metric='avg'):\n",
    "    noOfPlanes = len(discretePlanes)\n",
    "    angles = np.zeros((centroidMat.shape[0]*centroidMat.shape[1], noOfPlanes))\n",
    "#     centDist = np.sum(pPC, axis=1)\n",
    "    for i in range(centroidMat.shape[0]):\n",
    "        for j in range(centroidMat.shape[1]):\n",
    "            cent, evecs, evalue = project2D(centerData(centroidMat[i][j]))\n",
    "            PCAedCentroid = (np.dot(evecs.T, np.array(cent[0]).T)).T\n",
    "            a,b,c,d = getPlaneEquation(PCAedCentroid[0],PCAedCentroid[1],PCAedCentroid[2])\n",
    "            for k in range(noOfPlanes):\n",
    "                angles[centroidMat.shape[1]*i+j][k] = dihedralAngle(np.array([a,b,c]), discretePlanes[k])\n",
    "    probabilities = np.zeros((noOfPlanes, centroidMat.shape[0]))\n",
    "    for i in range(probabilities.shape[1]):\n",
    "        probabilities[:,i] = np.sum(angles[i*centroidMat.shape[1]:(i+1)*centroidMat.shape[1],:],axis=0)\n",
    "#     print(np.sum(probabilities, axis=1).shape)\n",
    "    probabilities = 1.0/probabilities\n",
    "    probabilities /= np.sum(probabilities, axis=1).reshape((-1,1))\n",
    "    \n",
    "    return probabilities\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# probability of Bundle given centroid and plane information\n",
    "# dimensions: ((no of centroids*no of discrete planes), no of bundles)\n",
    "def pB_PC(pBP, plane, centroid):\n",
    "    return pBP[plane]*pPC[centroid][plane]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "pBP = pB_P(pPC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(streamline):\n",
    "    l = np.argmax(np.random.random(centroidMat.shape[0]))\n",
    "    answers = []\n",
    "    probc = pC_S(streamline).flatten()\n",
    "    prevb = 0\n",
    "    for i in range(5000):\n",
    "        c = np.random.choice(np.arange(probc.shape[0]), p=probc)\n",
    "        probp = pPC[c,:]\n",
    "        p = np.random.choice(np.arange(probp.shape[0]), p=probp)\n",
    "        prob = pB_PC(pBP, p, c)\n",
    "        finalProb = prob*probc[c]*probp[p]\n",
    "        finalProb/=np.sum(finalProb)\n",
    "        l = (np.random.choice(np.arange(finalProb.shape[0]), p=finalProb))\n",
    "        answers.append(l)\n",
    "    return (np.bincount(answers[4000:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = []\n",
    "for i in range(200):\n",
    "    acc.append(np.argmax(predict(brain[i])))\n",
    "#     print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = np.array(acc)\n",
    "(np.sum(acc[:50]==0) + np.sum(acc[50:100]==1) + np.sum(acc[100:150]==2) + np.sum(acc[150:]==3))/200\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#show_streamlines(cst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#show_multiple_streamlines(bundle,cst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "let's see its data type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bundle # whole bundle, made of several streamlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ((brain)[0]).shape# number of streamlines in bundle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bundle[1] #one streamline in bundle\n",
    "# (np.array(bundle)[0]).shape\n",
    "# np.array(bundle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (bundle[1].shape) #one point on one streamline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "npbrain = np.array(brain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# npbrain[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(bundle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "these are x, y and z co-ordinates of the point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 100 200 300 400 500 600 700 800 900 1000 1100 1200 1300 1400 1500 1600 1700 1800 1900 "
     ]
    }
   ],
   "source": [
    "# get labels\n",
    "\n",
    "def getLabels(brain, bundle):\n",
    "    labels = np.zeros(len(brain))\n",
    "    npbrain = np.array(brain)\n",
    "    for i in range(len(bundle)):\n",
    "        for j in range(len(brain)):\n",
    "            if((npbrain[j].shape[0]==bundle[i].shape[0])):\n",
    "    #         print(i,j)\n",
    "                if np.allclose(npbrain[j], bundle[i]):\n",
    "                    labels[j] = 1\n",
    "                    break\n",
    "        if(i%100==0):\n",
    "            print(i,end=\" \")\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# npbrain[0].shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_pts = [len(streamline) for streamline in bundle]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dipy.tracking.streamline import (set_number_of_points, nbytes,select_random_set_of_streamlines)\n",
    "newStreamlines = set_number_of_points(bundle,101)\n",
    "n_pts_ds = [len(streamline) for streamline in newStreamlines]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newBrain = set_number_of_points(brain,101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(619,)"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# newBrain[0].shape\n",
    "trainset[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(npbrain)\n",
    "npbrain = np.array(brain1D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========\n",
    "#   MODEL\n",
    "# ==========\n",
    "\n",
    "# Parameters\n",
    "learning_rate = 0.02\n",
    "training_steps = 70\n",
    "batch_size = 100\n",
    "display_step = 200\n",
    "\n",
    "# Network Parameters\n",
    "seq_max_len = 1000 # Sequence max length\n",
    "n_hidden = 64 # hidden layer num of features\n",
    "n_classes = 2 # linear sequence or not\n",
    "\n",
    "trainset = npbrain[1950:2050]\n",
    "testset = labels[1950:2050]\n",
    "\n",
    "# tf Graph input\n",
    "x = tf.placeholder(\"float\", [None, seq_max_len, 3])\n",
    "y = tf.placeholder(\"float\", [None, n_classes])\n",
    "# A placeholder for indicating each sequence length\n",
    "seqlen = tf.placeholder(tf.int32, [None])\n",
    "\n",
    "# Define weights\n",
    "weights = {\n",
    "    'out': tf.Variable(tf.random_normal([n_hidden, n_classes]))\n",
    "}\n",
    "biases = {\n",
    "    'out': tf.Variable(tf.random_normal([n_classes]))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dynamicRNN(x, seqlen, weights, biases):\n",
    "    # Prepare data shape to match `rnn` function requirements\n",
    "    # Current data input shape: (batch_size, n_steps, n_input)\n",
    "    # Required shape: 'n_steps' tensors list of shape (batch_size, n_input)\n",
    "    \n",
    "    # Unstack to get a list of 'n_steps' tensors of shape (batch_size, n_input)\n",
    "    x = tf.unstack(x, seq_max_len, 1)\n",
    "\n",
    "    # Define a lstm cell with tensorflow\n",
    "    lstm_cell = tf.contrib.rnn.BasicLSTMCell(n_hidden)\n",
    "\n",
    "    # Get lstm cell output, providing 'sequence_length' will perform dynamic\n",
    "    # calculation.\n",
    "    outputs, states = tf.contrib.rnn.static_rnn(lstm_cell, x, dtype=tf.float32,\n",
    "                                sequence_length=seqlen)\n",
    "\n",
    "    # When performing dynamic calculation, we must retrieve the last\n",
    "    # dynamically computed output, i.e., if a sequence length is 10, we need\n",
    "    # to retrieve the 10th output.\n",
    "    # However TensorFlow doesn't support advanced indexing yet, so we build\n",
    "    # a custom op that for each sample in batch size, get its length and\n",
    "    # get the corresponding relevant output.\n",
    "\n",
    "    # 'outputs' is a list of output at every timestep, we pack them in a Tensor\n",
    "    # and change back dimension to [batch_size, n_step, n_input]\n",
    "    outputs = tf.stack(outputs)\n",
    "    outputs = tf.transpose(outputs, [1, 0, 2])\n",
    "\n",
    "    # Hack to build the indexing and retrieve the right output.\n",
    "    batch_size = tf.shape(outputs)[0]\n",
    "    # Start indices for each sample\n",
    "    index = tf.range(0, batch_size) * seq_max_len + (seqlen - 1)\n",
    "    # Indexing\n",
    "    outputs = tf.gather(tf.reshape(outputs, [-1, n_hidden]), index)\n",
    "\n",
    "    # Linear activation, using outputs computed above\n",
    "    return tf.matmul(outputs, weights['out']) + biases['out']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Placeholder', 'Placeholder_1', 'Placeholder_2', 'random_normal/shape', 'random_normal/mean', 'random_normal/stddev', 'random_normal/RandomStandardNormal', 'random_normal/mul', 'random_normal', 'Variable', 'Variable/Assign', 'Variable/read', 'random_normal_1/shape', 'random_normal_1/mean', 'random_normal_1/stddev', 'random_normal_1/RandomStandardNormal', 'random_normal_1/mul', 'random_normal_1', 'Variable_1', 'Variable_1/Assign', 'Variable_1/read', 'IsVariableInitialized', 'IsVariableInitialized_1', 'init']\n",
      "WARNING:tensorflow:From <ipython-input-122-1df78fe636d0>:10: BasicLSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is deprecated, please use tf.nn.rnn_cell.LSTMCell, which supports all the feature this cell currently has. Please replace the existing code with tf.nn.rnn_cell.LSTMCell(name='basic_lstm_cell').\n",
      "WARNING:tensorflow:From <ipython-input-123-3da1ac813a18>:12: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rp7/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:112: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    }
   ],
   "source": [
    "tf_session = keras.backend.get_session()\n",
    "tf_graph = tf.get_default_graph()\n",
    "# tf.reset_default_graph()\n",
    "print([n.name for n in tf.get_default_graph().as_graph_def().node])\n",
    "# tf.contrib.rnn.reset_states()\n",
    "# with tf_session.as_default():\n",
    "#      with tf_graph.as_default():\n",
    "#             tf.reset_default_graph() \n",
    "pred = dynamicRNN(x, seqlen, weights, biases)\n",
    "\n",
    "# Define loss and optimizer\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=pred, labels=y))\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "\n",
    "# Evaluate model\n",
    "correct_pred = tf.equal(tf.argmax(pred,1), tf.argmax(y,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "\n",
    "# Initialize the variables (i.e. assign their default value)\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-124-4f01eda86ce6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;31m# Run optimization op (backprop)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         sess.run(optimizer, feed_dict={x: batch_x, y: batch_y,\n\u001b[0;32m---> 27\u001b[0;31m                                        seqlen: batch_seqlen})\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mdisplay_step\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m             \u001b[0;31m# Calculate batch accuracy & loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    927\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 929\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    930\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1119\u001b[0m             \u001b[0mfeed_handles\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msubfeed_t\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msubfeed_val\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1120\u001b[0m           \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1121\u001b[0;31m             \u001b[0mnp_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubfeed_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msubfeed_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m           if (not is_tensor_handle_feed and\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/numpy/core/numeric.py\u001b[0m in \u001b[0;36masarray\u001b[0;34m(a, dtype, order)\u001b[0m\n\u001b[1;32m    499\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    500\u001b[0m     \"\"\"\n\u001b[0;32m--> 501\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    502\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: setting an array element with a sequence."
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "\n",
    "    # Run the initializer\n",
    "    sess.run(init)\n",
    "\n",
    "    for step in range(1, training_steps+1):\n",
    "#         batch_x, batch_y, batch_seqlen = trainset.next(batch_size)\n",
    "        rangelow = ((step-1)*batch_size)%(trainset.shape[0])\n",
    "        rangehigh = ((step)*batch_size)%(trainset.shape[0])\n",
    "        if(rangehigh==rangelow):\n",
    "            rangehigh=rangehigh-1\n",
    "        if(rangehigh<rangelow):\n",
    "            batch_x = np.append(trainset[rangelow:], trainset[:rangehigh])\n",
    "            batch_y = np.append(testset[rangelow:], testset[:rangehigh])\n",
    "        else:\n",
    "            batch_x = trainset[rangelow:rangehigh]\n",
    "            batch_y = testset[rangelow:rangehigh]\n",
    "        \n",
    "        batch_seqlen = []\n",
    "        for sample in trainset:\n",
    "            batch_seqlen.append(sample.shape[0])\n",
    "\n",
    "#         batch_seqlen = batch_seqlen.tolist()\n",
    "        print(type(batch_seqlen))\n",
    "        # Run optimization op (backprop)\n",
    "        sess.run(optimizer, feed_dict={x: batch_x, y: batch_y,\n",
    "                                       seqlen: batch_seqlen})\n",
    "        if step % display_step == 0 or step == 1:\n",
    "            # Calculate batch accuracy & loss\n",
    "            acc, loss = sess.run([accuracy, cost], feed_dict={x: batch_x, y: batch_y,\n",
    "                                                seqlen: batch_seqlen})\n",
    "            print(\"Step \" + str(step) + \", Minibatch Loss= \" + \\\n",
    "                  \"{:.6f}\".format(loss) + \", Training Accuracy= \" + \\\n",
    "                  \"{:.5f}\".format(acc))\n",
    "\n",
    "    print(\"Optimization Finished!\")\n",
    "\n",
    "    # Calculate accuracy\n",
    "    test_data = testset.data\n",
    "    test_label = testset.labels\n",
    "    test_seqlen = testset.seqlen\n",
    "    print(\"Testing Accuracy:\", \\\n",
    "        sess.run(accuracy, feed_dict={x: test_data, y: test_label,\n",
    "                                      seqlen: test_seqlen}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ToySequenceData(object):\n",
    "    \"\"\" Generate sequence of data with dynamic length.\n",
    "    This class generate samples for training:\n",
    "    - Class 0: linear sequences (i.e. [0, 1, 2, 3,...])\n",
    "    - Class 1: random sequences (i.e. [1, 3, 10, 7,...])\n",
    "\n",
    "    NOTICE:\n",
    "    We have to pad each sequence to reach 'max_seq_len' for TensorFlow\n",
    "    consistency (we cannot feed a numpy array with inconsistent\n",
    "    dimensions). The dynamic calculation will then be perform thanks to\n",
    "    'seqlen' attribute that records every actual sequence length.\n",
    "    \"\"\"\n",
    "    def __init__(self, n_samples=1000, max_seq_len=20, min_seq_len=3,\n",
    "                 max_value=1000):\n",
    "        self.data = []\n",
    "        self.labels = []\n",
    "        self.seqlen = []\n",
    "        for i in range(n_samples):\n",
    "            # Random sequence length\n",
    "            len = np.random.randint(min_seq_len, max_seq_len)\n",
    "            # Monitor sequence length for TensorFlow dynamic calculation\n",
    "            self.seqlen.append(len)\n",
    "            # Add a random or linear int sequence (50% prob)\n",
    "            if np.random.random() < .5:\n",
    "                # Generate a linear sequence\n",
    "                rand_start = np.random.randint(0, max_value - len)\n",
    "                s = [[float(i)/max_value] for i in\n",
    "                     range(rand_start, rand_start + len)]\n",
    "                # Pad sequence for dimension consistency\n",
    "                s += [[0.] for i in range(max_seq_len - len)]\n",
    "                self.data.append(s)\n",
    "                self.labels.append([1., 0.])\n",
    "            else:\n",
    "                # Generate a random sequence\n",
    "                s = [[float(np.random.randint(0, max_value))/max_value]\n",
    "                     for i in range(len)]\n",
    "                # Pad sequence for dimension consistency\n",
    "                s += [[0.] for i in range(max_seq_len - len)]\n",
    "                self.data.append(s)\n",
    "                self.labels.append([0., 1.])\n",
    "        self.batch_id = 0\n",
    "\n",
    "    def next(self, batch_size):\n",
    "        \"\"\" Return a batch of data. When dataset end is reached, start over.\n",
    "        \"\"\"\n",
    "        if self.batch_id == len(self.data):\n",
    "            self.batch_id = 0\n",
    "        batch_data = (self.data[self.batch_id:min(self.batch_id +\n",
    "                                                  batch_size, len(self.data))])\n",
    "        batch_labels = (self.labels[self.batch_id:min(self.batch_id +\n",
    "                                                  batch_size, len(self.data))])\n",
    "        batch_seqlen = (self.seqlen[self.batch_id:min(self.batch_id +\n",
    "                                                  batch_size, len(self.data))])\n",
    "        print(type(batch_seqlen[0]))\n",
    "        self.batch_id = min(self.batch_id + batch_size, len(self.data))\n",
    "        return batch_data, batch_labels, batch_seqlen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr = ToySequenceData(n_samples=1000, max_seq_len=seq_max_len)\n",
    "te = ToySequenceData(n_samples=500, max_seq_len=seq_max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b_x, b_y, b_seqlen = tr.next(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print((b_x))\n",
    "# print(batch_seqlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
